{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning LAB 3: LINEAR REGRESSION\n",
    "\n",
    "Course 2024/25: *F. Chiariotti*\n",
    "\n",
    "The notebook contains some simple tasks to be performed with **LINEAR REGRESSION MODELS**.\n",
    "\n",
    "Complete all the **required code sections**.\n",
    "\n",
    "### IMPORTANT for the exam:\n",
    "\n",
    "The functions you might be required to implement in the exam will have the same signature and parameters as the ones in the labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VR traffic prediction\n",
    "\n",
    "In this notebook, we will explore the prediction of Virtual Reality (VR) traffic. The data come from the paper:\n",
    "\n",
    "Lecci, Mattia, _et al._ \"An open framework for analyzing and modeling XR network traffic.\" IEEE Access 9 (2021): 129782-129795.\n",
    "\n",
    "The VR game Virus Popper was instantiated on a computer through the RiftCat application: the user could then see the virtual content on their phone, which was strapped to their head with a Cardboard viewer. The file virus_popper.csv contains three columns from the traffic capture:\n",
    "idx    | frame size (B) |  time (s)\n",
    "0      | 38424          |  0.0\n",
    "1      | 39801          |  0.01944\n",
    "...\n",
    "\n",
    "The game was run at 60 frames per second, with a target rate of 30 Mb/s. The task is then to predict the size of the next frame, given the past N frames. This was explored in another paper:\n",
    "\n",
    "Chiariotti, Federico, _et al._ \"Temporal characterization and prediction of vr traffic: A network slicing use case.\" IEEE Transactions on Mobile Computing 23.5 (2023): 3890-3908.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the necessary Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39801, 38983, 38890, ..., 61156, 61630, 58815])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def load_dataset(filename):\n",
    "    data_train = pd.read_csv(filename)\n",
    "    data = data_train.iloc[:, 1].values # Get the second column (frame size) as the input\n",
    "    return data\n",
    "\n",
    "# Load the dataset\n",
    "data = load_dataset('data/virus_popper.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data and create training and test sets\n",
    "\n",
    "In this case, we are learning a time series: let us consider a memory of 2 samples, i.e., use X[n-1] and X[n-2] to predict X[n]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25878, 3) (25878,) (8625, 3) (8625,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.64216647, 0.62896851],\n",
       "       [1.        , 0.62896851, 0.627468  ],\n",
       "       [1.        , 0.627468  , 0.62251473],\n",
       "       ...,\n",
       "       [1.        , 1.16737445, 1.00077032],\n",
       "       [1.        , 1.00077032, 1.08186197],\n",
       "       [1.        , 1.08186197, 1.07116484]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the dataset\n",
    "avg_size = np.mean(data)\n",
    "norm_data = np.asarray(data) / avg_size\n",
    "\n",
    "# Compute the splits and prepare the columns\n",
    "m_training = int(0.75*norm_data.shape[0])\n",
    "\n",
    "X_training = np.ones([m_training - 2, 3])\n",
    "\n",
    "X_training[:,1] = norm_data[: m_training - 2]\n",
    "X_training[:,2] = norm_data[1 : m_training - 1]\n",
    "Y_training = norm_data[2 : m_training]\n",
    "\n",
    "\n",
    "X_test = np.ones([norm_data.shape[0] - m_training - 2, 3])\n",
    "X_test[:,1] = norm_data[m_training : -2]\n",
    "X_test[:,2] = norm_data[m_training + 1 : -1]\n",
    "Y_test = norm_data[m_training + 2:]\n",
    "\n",
    "print(np.shape(X_training), np.shape(Y_training), np.shape(X_test), np.shape(Y_test))\n",
    "\n",
    "X_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares linear regression\n",
    "\n",
    "Train and evaluate the LS regressor on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least squares solution\n",
    "def least_squares(X_matrix: np.ndarray, labels: np.ndarray) -> None:\n",
    "    ## TODO: Run the LS algorithm without regularization\n",
    "\n",
    "    A = np.transpose(X_matrix).dot(X_matrix)\n",
    "    b = labels.dot(X_matrix)\n",
    "\n",
    "    w = np.linalg.inv(A).dot(b)\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "def evaluate_model(x, y, coeff):\n",
    "    ## TODO: Return the average MSE for the set over which we evaluate\n",
    "\n",
    "    y_pred = np.dot(x, coeff)\n",
    "\n",
    "    Eval = np.sum((y_pred - y)**2)/x.shape[0]\n",
    "\n",
    "    return Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model coefficients: [0.36986742 0.20348677 0.42565451]\n",
      "Root MSE: 7712.354721539114\n"
     ]
    }
   ],
   "source": [
    "# Run the LS training and test it on the test data\n",
    "trained_model = least_squares(X_training, Y_training)\n",
    "mse = evaluate_model(X_test, Y_test, trained_model)\n",
    "print('Model coefficients:', trained_model)\n",
    "print('Root MSE:', np.sqrt(mse) * avg_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares with Tikhonov regularization\n",
    "\n",
    "Perform K-fold cross validation with $\\lambda\\in\\{0, 0.1, 1, 10\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least squares solution\n",
    "def regularized_least_squares(X_matrix: np.ndarray, labels: np.ndarray, lambda_par: np.ndarray) -> None:\n",
    "    ## TODO: Run the LS algorithm with regularization\n",
    "\n",
    "  A = np.transpose(X_matrix).dot(X_matrix)\n",
    "  b = labels.dot(X_matrix)\n",
    "\n",
    "  w = np.linalg.inv(2*lambda_par*np.eye(labels.shape[0])*labels.shape[0] + A).dot(b)\n",
    "\n",
    "  return w\n",
    "\n",
    "\n",
    "\n",
    "def K_fold(X_training: np.ndarray, Y_training: np.ndarray, lambda_vec: np.ndarray, K: np.ndarray) -> None:\n",
    "    ## TODO: Perform K-fold cross-validation\n",
    "\n",
    "\n",
    "    indices = np.arange(X_training.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    #!\n",
    "    folds = np.array_split(indices, K)\n",
    "    Error = []\n",
    "\n",
    "    for L in lambda_vec:   \n",
    "      W = []\n",
    "\n",
    "      for i in range(K):\n",
    "\n",
    "        val = folds[i]\n",
    "        train = np.concatenate(folds[:i] + folds[i+1:])\n",
    "\n",
    "        X_train, Y_train = X_training[train], Y_training[train]\n",
    "        X_val, Y_val = X_training[val], Y_training[val]\n",
    "         \n",
    "        w = regularized_least_squares(X_train, Y_train, L)\n",
    "        error = evaluate_model(X_val, Y_val, w)\n",
    "\n",
    "        Error.append(error)\n",
    "\n",
    "\n",
    "      argmin = np.argmin(Error)\n",
    "      best_error = Error[argmin]\n",
    "      best_L = lambda_vec[argmin]\n",
    "\n",
    "    return best_L, best_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (20702,20702) (3,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      2\u001b[0m lambda_par \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m21\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m bestL, bestError \u001b[38;5;241m=\u001b[39m K_fold(X_training, Y_training, lambda_par, K)\n",
      "Cell \u001b[0;32mIn[27], line 35\u001b[0m, in \u001b[0;36mK_fold\u001b[0;34m(X_training, Y_training, lambda_vec, K)\u001b[0m\n\u001b[1;32m     32\u001b[0m X_train, Y_train \u001b[38;5;241m=\u001b[39m X_training[train], Y_training[train]\n\u001b[1;32m     33\u001b[0m X_val, Y_val \u001b[38;5;241m=\u001b[39m X_training[val], Y_training[val]\n\u001b[0;32m---> 35\u001b[0m w \u001b[38;5;241m=\u001b[39m regularized_least_squares(X_train, Y_train, L)\n\u001b[1;32m     36\u001b[0m error \u001b[38;5;241m=\u001b[39m evaluate_model(X_val, Y_val, w)\n\u001b[1;32m     38\u001b[0m Error\u001b[38;5;241m.\u001b[39mappend(error)\n",
      "Cell \u001b[0;32mIn[27], line 8\u001b[0m, in \u001b[0;36mregularized_least_squares\u001b[0;34m(X_matrix, labels, lambda_par)\u001b[0m\n\u001b[1;32m      5\u001b[0m A \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(X_matrix)\u001b[38;5;241m.\u001b[39mdot(X_matrix)\n\u001b[1;32m      6\u001b[0m b \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mdot(X_matrix)\n\u001b[0;32m----> 8\u001b[0m w \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mlambda_par\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39meye(labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m*\u001b[39mlabels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m A)\u001b[38;5;241m.\u001b[39mdot(b)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m w\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (20702,20702) (3,3) "
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "lambda_par = range(21)\n",
    "\n",
    "bestL, bestError = K_fold(X_training, Y_training, lambda_par, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training with K-fold cross-validation and plot the score\n",
    "K = 5\n",
    "lambda_par = range(21)\n",
    "\n",
    "best_model, best_perf, models, results = K_fold(X_training, Y_training, lambda_par, K)\n",
    "print(best_model, results)\n",
    "plt.plot(lambda_par, np.sqrt(results) * avg_size)\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results for the regularized models on the test set\n",
    "test_scores = np.zeros(len(models))\n",
    "\n",
    "for i in range(len(models)):\n",
    "    test_scores[i] = evaluate_model(X_test, Y_test, models[i])\n",
    "\n",
    "plt.plot(lambda_par, np.sqrt(test_scores) * avg_size)\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRA\n",
    "\n",
    "Can you figure out the best amount of memory to use?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
